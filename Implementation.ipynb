{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing punctuation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I am running in the park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb                           I am running in the park"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing punctuation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then youll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>From RfC  \\n\\n The title is fine as it is IMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\\n\\n  Sources  \\n\\n  Zawe Ashton on Lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>If you have a look back at the source the info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I am running in the park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then youll ...\n",
       "1  0000247867823ef7      From RfC  \\n\\n The title is fine as it is IMO\n",
       "2  00013b17ad220c46   \\n\\n  Sources  \\n\\n  Zawe Ashton on Lapland     \n",
       "3  00017563c3f7919a  If you have a look back at the source the info...\n",
       "4  00017695ad8997eb                           I am running in the park"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load the data from 'test.csv' into a DataFrame\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Display the first few rows before removing punctuation to see the original data\n",
    "print(\"Before removing punctuation:\")\n",
    "display(test_data.head())\n",
    "\n",
    "# Remove punctuation using regex\n",
    "# The following pattern will match any character that is not a word character (\\w), whitespace (\\s), or apostrophe (')\n",
    "# You can adjust the regex pattern according to your specific requirements\n",
    "test_data['comment_text'] = test_data['comment_text'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# Display the first few rows after removing punctuation to verify the changes\n",
    "print(\"\\nAfter removing punctuation:\")\n",
    "\n",
    "display(test_data.head())\n",
    "output_file_path1 = 'processed_test_data1.csv'\n",
    "test_data.to_csv(output_file_path1, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\OUSSAMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\OUSSAMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\OUSSAMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After lemmatization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule be more succesful then youll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>From RfC The title be fine a it be IMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>Sources Zawe Ashton on Lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>If you have a look back at the source the info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I be run in the park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule be more succesful then youll ...\n",
       "1  0000247867823ef7             From RfC The title be fine a it be IMO\n",
       "2  00013b17ad220c46                     Sources Zawe Ashton on Lapland\n",
       "3  00017563c3f7919a  If you have a look back at the source the info...\n",
       "4  00017695ad8997eb                               I be run in the park"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Ensure that NLTK's WordNet, tokenizer, and POS tagger resources are downloaded\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Helper function to convert nltk POS to wordnet POS\n",
    "def get_wordnet_pos(nltk_pos):\n",
    "    if nltk_pos.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_pos.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_pos.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_pos.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Define a function to lemmatize text with correct POS tagging\n",
    "def lemmatize_text(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    # Get POS tags for the words\n",
    "    pos_tags = pos_tag(words)\n",
    "    # Lemmatize each word with the correct POS\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags]\n",
    "    # Join the lemmatized words back into a string\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Apply the lemmatization function to the 'comment_text' column\n",
    "test_data['comment_text'] = test_data['comment_text'].astype(str)  # Ensure the column is string type\n",
    "test_data['comment_text'] = test_data['comment_text'].apply(lemmatize_text)\n",
    "\n",
    "# Display the first few rows after lemmatization to verify the changes\n",
    "print(\"\\nAfter lemmatization:\")\n",
    "display(test_data.head())\n",
    "\n",
    "# Save the processed data to a new CSV file\n",
    "output_file_path2 = 'processed_test_data2.csv'\n",
    "test_data.to_csv(output_file_path2, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\OUSSAMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\OUSSAMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing stopwords:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule succesful youll ever whats ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>RfC title fine IMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>Sources Zawe Ashton Lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>look back source information update correct fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>run park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule succesful youll ever whats ha...\n",
       "1  0000247867823ef7                                 RfC title fine IMO\n",
       "2  00013b17ad220c46                        Sources Zawe Ashton Lapland\n",
       "3  00017563c3f7919a  look back source information update correct fo...\n",
       "4  00017695ad8997eb                                           run park"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download the NLTK stopwords resource if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load English stopwords from NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define a function to remove stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    # Filter out any words that are in the list of stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    # Join the filtered words back into a single string\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the remove_stopwords function to the 'comment_text' column\n",
    "test_data['comment_text'] = test_data['comment_text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the first few rows after stopword removal to verify the changes\n",
    "print(\"\\nAfter removing stopwords:\")\n",
    "display(test_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path3 = 'processed_test_data3.csv'\n",
    "test_data.to_csv(output_file_path3, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names (words or tokens):\n",
      "['00' '000' '0000' ... 'ｙｏｕｒ' 'ｙｏｕｒｓｅｌｆ' '𨳒你老母个閪']\n",
      "\n",
      "Number of unique features (words or tokens): 294386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Assume 'test_data' is your DataFrame and 'comment_text' is the column with processed text\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(test_data['comment_text'])\n",
    "\n",
    "# Retrieve the feature names (words or tokens)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print()\n",
    "# Display the feature names\n",
    "print(\"Feature names (words or tokens):\")\n",
    "print(feature_names)\n",
    "\n",
    "# Optionally, display the number of features\n",
    "print(\"\\nNumber of unique features (words or tokens):\", len(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial view of the TF-IDF matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000000</th>\n",
       "      <th>00000000</th>\n",
       "      <th>0000000000000000000000000000</th>\n",
       "      <th>000000000000000000000000000000000fdgkja</th>\n",
       "      <th>000000000000111265005605361866087675053350036566001020343907867982125026173889636993408203125</th>\n",
       "      <th>0000001</th>\n",
       "      <th>00000010</th>\n",
       "      <th>...</th>\n",
       "      <th>00085</th>\n",
       "      <th>0009</th>\n",
       "      <th>00090</th>\n",
       "      <th>00095</th>\n",
       "      <th>0009png</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>00100</th>\n",
       "      <th>00105</th>\n",
       "      <th>0011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  0000  000000  00000000  0000000000000000000000000000   \n",
       "0  0.0  0.0   0.0     0.0       0.0                           0.0  \\\n",
       "1  0.0  0.0   0.0     0.0       0.0                           0.0   \n",
       "2  0.0  0.0   0.0     0.0       0.0                           0.0   \n",
       "3  0.0  0.0   0.0     0.0       0.0                           0.0   \n",
       "4  0.0  0.0   0.0     0.0       0.0                           0.0   \n",
       "\n",
       "   000000000000000000000000000000000fdgkja   \n",
       "0                                      0.0  \\\n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "\n",
       "   000000000000111265005605361866087675053350036566001020343907867982125026173889636993408203125   \n",
       "0                                                0.0                                              \\\n",
       "1                                                0.0                                               \n",
       "2                                                0.0                                               \n",
       "3                                                0.0                                               \n",
       "4                                                0.0                                               \n",
       "\n",
       "   0000001  00000010  ...  00085  0009  00090  00095  0009png  001  0010   \n",
       "0      0.0       0.0  ...    0.0   0.0    0.0    0.0      0.0  0.0   0.0  \\\n",
       "1      0.0       0.0  ...    0.0   0.0    0.0    0.0      0.0  0.0   0.0   \n",
       "2      0.0       0.0  ...    0.0   0.0    0.0    0.0      0.0  0.0   0.0   \n",
       "3      0.0       0.0  ...    0.0   0.0    0.0    0.0      0.0  0.0   0.0   \n",
       "4      0.0       0.0  ...    0.0   0.0    0.0    0.0      0.0  0.0   0.0   \n",
       "\n",
       "   00100  00105  0011  \n",
       "0    0.0    0.0   0.0  \n",
       "1    0.0    0.0   0.0  \n",
       "2    0.0    0.0   0.0  \n",
       "3    0.0    0.0   0.0  \n",
       "4    0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Initialize the TF-IDF transformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# Apply the TF-IDF transformation to the Bag-of-Words matrix\n",
    "X_tfidf = tfidf_transformer.fit_transform(X)\n",
    "\n",
    "tfidf_part_df = pd.DataFrame(X_tfidf[:5, :100].toarray(), columns=feature_names[:100])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Partial view of the TF-IDF matrix:\")\n",
    "display(tfidf_part_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
